{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ashmitchamoli/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "import glob\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from typing import Literal\n",
    "from PIL import Image\n",
    "\n",
    "from lib.driving_dataset.DrivingDataset import DrivingDataset, Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(videoName : str, split : Literal['train', 'dev', 'test']) -> DrivingDataset:\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = DrivingDataset('test_video', 'train')\n",
    "model = timm.create_model('mobilenetv3_large_100', pretrained=True, num_classes=trainDataset.numClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10770 images\n",
      "Creating the dataset and dataloader\n",
      "Creating the dataloader\n",
      "Training the model\n",
      "Epoch 1\n",
      "Train Loss: 0.14908532349912912\n",
      "Train Accuracy: 96.46007428040855%\n",
      "Validation Accuracy: 96.64706489219024%\n",
      "Epoch 2\n",
      "Train Loss: 0.06959705077451239\n",
      "Train Accuracy: 98.46796657381616%\n",
      "Validation Accuracy: 98.545341999381%\n",
      "Epoch 3\n",
      "Train Loss: 0.04158960040345988\n",
      "Train Accuracy: 99.21077065923862%\n",
      "Validation Accuracy: 99.2056122975343%\n",
      "Epoch 4\n",
      "Train Loss: 0.03294906490897498\n",
      "Train Accuracy: 99.21077065923862%\n",
      "Validation Accuracy: 99.21592902094295%\n",
      "Epoch 5\n",
      "Train Loss: 0.024641239710160717\n",
      "Train Accuracy: 99.45450324976787%\n",
      "Validation Accuracy: 99.48416382956773%\n",
      "Finished Training\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MobileNetV3' object has no attribute 'module'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 104\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;66;03m# Save the model\u001b[39;00m\n\u001b[1;32m    103\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/\u001b[39m\u001b[38;5;124m\"\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 104\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/classifier.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Test the model\u001b[39;00m\n\u001b[1;32m    107\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MobileNetV3' object has no attribute 'module'"
     ]
    }
   ],
   "source": [
    "videoName = 'test_video'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "imagePaths = glob.glob(f'./Datasets/SynDDAnnotated/{videoName}/frames/*.jpg')\n",
    "print(f\"Loaded {len(imagePaths)} images\")\n",
    "\n",
    "def getLabel(imagePath): \n",
    "    class_label = imagePath.split('/')[-1].split('_')[1]\n",
    "    class_label = int(float(class_label)) if class_label != \"nan\" else 0  \n",
    "    return class_label\n",
    "\n",
    "class ImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_paths, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = getLabel(image_path)\n",
    "        return image, label\n",
    "    \n",
    "# Define the transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Creating the dataset and dataloader\")\n",
    "# Create the dataset\n",
    "dataset = ImageDataset(imagePaths, transform=transform)\n",
    "\n",
    "print(\"Creating the dataloader\")\n",
    "# Make train, test, validation splits\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = int(0.1 * len(dataset))\n",
    "val_size = len(dataset) - train_size - test_size\n",
    "train_dataset, test_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, test_size, val_size])\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Only train the classifier parameters\n",
    "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "print(\"Training the model\")\n",
    "# Train the model\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(5):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)  # Move data to GPU\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # if i % 20 == 0:\n",
    "        #     print(f\"Train Loss: {running_loss / 20}\")\n",
    "        #     print(f\"Train Accuracy: {100 * correct / total}%\")\n",
    "        #     running_loss = 0.0\n",
    "        #     total = 0\n",
    "        #     correct = 0\n",
    "    running_loss = running_loss / len(train_dataloader)\n",
    "    print(f\"Train Loss: {running_loss}\")\n",
    "    print(f\"Train Accuracy: {100 * correct / total}%\")\n",
    "\n",
    "    for i, data in enumerate(val_dataloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)  # Move data to GPU\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Validation Accuracy: {100 * correct / total}%\")\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1077 test images: 99.44289693593315%\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "os.makedirs(\"./models/\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"./models/classifier.pth\")\n",
    "\n",
    "# Test the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)  # Move data to GPU\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy of the network on the {total} test images: {100 * correct / total}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
